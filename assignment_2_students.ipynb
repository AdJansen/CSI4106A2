{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13020), started 1:25:27 ago. (Use '!kill 13020' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2350f82dd9c590bc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2350f82dd9c590bc\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for reproducibility purposes\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# load tensorboard extension\n",
    "%reload_ext tensorboard\n",
    "# specify the log directory where the tensorboard logs will be written\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the relevant datasets (15/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data shape: \n",
      "(15026, 4)\n",
      "\n",
      "Val Data shape: \n",
      "(3757, 4)\n",
      "\n",
      "Test Data shape: \n",
      "(4696, 4)\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Train Data coloumns: \n",
      "['age' 'ethnicity' 'gender' 'img_name']\n",
      "\n",
      "Val Data coloumns: \n",
      "['age' 'ethnicity' 'gender' 'img_name']\n",
      "\n",
      "Test Data coloumns: \n",
      "['age' 'ethnicity' 'gender' 'img_name']\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Train Data Gender Distribution:\n",
      "0    7864\n",
      "1    7162\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "Val Data Gender Distribution:\n",
      "0    1965\n",
      "1    1792\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "Test Data Gender Distribution:\n",
      "0    2456\n",
      "1    2240\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Train Data Ethnicity Distribution:\n",
      "0    6372\n",
      "1    2869\n",
      "3    2524\n",
      "2    2186\n",
      "4    1075\n",
      "Name: ethnicity, dtype: int64\n",
      "\n",
      "Val Data Ethnicity Distribution:\n",
      "0    1593\n",
      "1     717\n",
      "3     632\n",
      "2     547\n",
      "4     268\n",
      "Name: ethnicity, dtype: int64\n",
      "\n",
      "Test Data Ethnicity Distribution:\n",
      "0    1991\n",
      "1     896\n",
      "3     790\n",
      "2     683\n",
      "4     336\n",
      "Name: ethnicity, dtype: int64\n",
      "\n",
      "_____________________________________________\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Index.to_flat_index of Int64Index([ 26,   1,  28,  35,  24,  30,  25,  32,  29,  27,\n",
       "            ...\n",
       "             95,  99,  87, 100,  93, 116,  91, 111, 115, 110],\n",
       "           dtype='int64', length=101)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the datasets using the csv files train, val and test \n",
    "# (3)\n",
    "dfTrain = pd.read_csv('./data/train.csv')\n",
    "dfVal = pd.read_csv('./data/val.csv')\n",
    "dfTest = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# print the shapes of the dataframes \n",
    "# (3)\n",
    "print(f\"Train Data shape: \\n{dfTrain.shape}\\n\")\n",
    "print(f\"Val Data shape: \\n{dfVal.shape}\\n\")\n",
    "print(f\"Test Data shape: \\n{dfTest.shape}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the column names from either one of the dataframes \n",
    "# (1)\n",
    "print(f\"Train Data coloumns: \\n{dfTrain.columns.values}\\n\")\n",
    "print(f\"Val Data coloumns: \\n{dfVal.columns.values}\\n\")\n",
    "print(f\"Test Data coloumns: \\n{dfTest.columns.values}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the proportional distribution of gender in all three datasets(i.e., number of male and female) \n",
    "# (3)\n",
    "print(f\"Train Data Gender Distribution:\\n{dfTrain['gender'].value_counts()}\\n\")\n",
    "print(f\"Val Data Gender Distribution:\\n{dfVal['gender'].value_counts()}\\n\")\n",
    "print(f\"Test Data Gender Distribution:\\n{dfTest['gender'].value_counts()}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the proportional distribution of ethnicity in all three datasets \n",
    "# (3)\n",
    "print(f\"Train Data Ethnicity Distribution:\\n{dfTrain['ethnicity'].value_counts()}\\n\")\n",
    "print(f\"Val Data Ethnicity Distribution:\\n{dfVal['ethnicity'].value_counts()}\\n\")\n",
    "print(f\"Test Data Ethnicity Distribution:\\n{dfTest['ethnicity'].value_counts()}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# plot the age distribution from the training dataset where the x-axis plots the age and the y-axis depicts the count of individuals within each age group. For example, individuals with age=1 are: \n",
    "# (2)\n",
    "\n",
    "dfTrain['age'].value_counts().index\n",
    "#graph = dfTrain.plot.bar(x=dfTrain['age'].value_counts().index, y=dfTrain['age'].value_counts().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the ImageDataGenerators (22/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "enumerate() missing required argument 'iterable' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32004/2616688686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# enumerate through the validation data generator created above and plot first grayscale image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# (2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;31m# TODO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: enumerate() missing required argument 'iterable' (pos 1)"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator is an iterator.\n",
    "\n",
    "# specify the batch size hyperparameter. You can experiment with different batch sizes\n",
    "batch_size = 16\n",
    "\n",
    "# create the ImageDataGenerator with rescaling that will generate batched tensors representing images with real-time data augmentation\n",
    "# use at least two of the augmentation strategies. For example, fill_mode='nearest'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (3)\n",
    "train_img_gen = ImageDataGenerator(\n",
    "   # TODO\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance to link the image folder and the dataframe.\n",
    "# also include the, batch size, image size and the seed.\n",
    "# make sure to include the following arguments\n",
    "# color_mode='grayscale', class_mode='multi_output'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (5)\n",
    "# TODO\n",
    "\n",
    "\n",
    "# similarly, create an ImageDataGenerator for the validation dataset and make sure not to use any of th eaugmentation strategies except rescaling the image\n",
    "# (2)\n",
    "val_img_gen = ImageDataGenerator(\n",
    "    # TODO\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance with the same arguments as above\n",
    "# make sure to specify the following arguments:\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "# TODO\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the val_img_gen instance to link the test dataframe and the test data folder\n",
    "# In addition, make sure to specify the following arguments\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "# TODO\n",
    "\n",
    "\n",
    "# enumerate through the validation data generator created above and plot first grayscale image \n",
    "# (2)\n",
    "for i, element in enumerate():\n",
    "    # TODO\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model (44/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the model input with the required shape \n",
    "# (1)\n",
    "# TODO\n",
    "\n",
    "# The shared layers\n",
    "# Include at least one Conv2D layer, MaxPooling2D layer and a Flatten layer\n",
    "# you can have as many layers as possible, but make sure not to overfit your model using the training data\n",
    "# TODO\n",
    "# (10)\n",
    "\n",
    "# Task specific layers\n",
    "# Include at least one Dense layer as a task specific layer before generating the output for age\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# Include the age output and make sure to include the following arguments\n",
    "# activation='linear', name='xxx'(any name)\n",
    "# make sure to name your output layers so that different metrics to be used can be linked accordingly\n",
    "# please note that the age prediction is a regression task\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for ethnicity prediction\n",
    "# TODO\n",
    "# (2)\n",
    "# Include the ethnicity output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a multi-class classification task\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for gender prediction\n",
    "# TODO\n",
    "# (2)\n",
    "# Include the gender output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a binary classification task\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# create the model with the required input and the outputs.\n",
    "# pelase make sure that the outputs can be included in a list and make sure to keep note of the order\n",
    "# TODO\n",
    "# (3)\n",
    "\n",
    "# print the model summary\n",
    "# TODO\n",
    "# (0.5)\n",
    "\n",
    "# Instantiate the optimizer with the learning rate. You can start with the learning rate 1e-3(0.001).\n",
    "# Both the optimizer and the learning rate are hyperparameters that you can finetune\n",
    "# For example, you can start with the \"RMSprop\" optimizer\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# specify the losses to be used for each task: age, ethnicity and gender prediction \n",
    "# (0.5)\n",
    "losses = []\n",
    "# compile the model with the optimizer, loss, loss_weights and the metrics for each task\n",
    "# apply the following weights to the losses to balance the contribution of each loss to the total loss\n",
    "# loss_weights=[0.001, 0.5, 0.5]\n",
    "# please remember to use the relevant metric for each task by assigning it to the correct output\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# Define the callbacks\n",
    "# EarlyStopping: monitor the validation loss while waiting for 3 epochs before stopping\n",
    "# can restore the best weights\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "# reduce the learning rate by a factor of 0.1 after waiting for 2 epochs while monitoring validation loss\n",
    "# specify a minimum learning rate to be used\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "# In addition please specify the following arguments\n",
    "# steps_per_epoch=len(df_train)/batch_size\n",
    "# validation_steps=len(df_val)/batch_size\n",
    "# (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions on test data (14/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the trained model using the test generator\n",
    "# print only the test accuracy for ethnicity and gender predictions\n",
    "(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions using the test generator\n",
    "(2)\n",
    "\n",
    "# extract the ethnicity predictions\n",
    "(2)\n",
    "# print the classification report for predicting ethnicity\n",
    "(2)\n",
    "\n",
    "# extract the gender predictions where probabilities above 0.5 are considered class 1 and if not, class 0\n",
    "(2)\n",
    "# print the classification report for predicting gender\n",
    "(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Present prediction results on test data(5/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present your findings for 5 different runs by fine-tuning the hyperparameters. The results table must contain the following fields\n",
    "- A minimum of 5 hyperparameters that you have fine-tuned\n",
    "- Mean absolute error for age\n",
    "- Accuracy for ethnicity prediction\n",
    "- Accuracy for gender prediction\n",
    "Please use a table format similar to the one mentioned below when presenting the results.\n",
    "\n",
    "| Hyperparameters | Age(MAE) | Ethnicity(Accuracy)| Gender(Accuracy) |\n",
    "|-----------------|----------|--------------------|------------------|\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
