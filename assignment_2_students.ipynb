{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13020), started 4 days, 9:46:21 ago. (Use '!kill 13020' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-64600360999a2b91\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-64600360999a2b91\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for reproducibility purposes\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# load tensorboard extension\n",
    "%reload_ext tensorboard\n",
    "# specify the log directory where the tensorboard logs will be written\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the relevant datasets (15/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data shape: \n",
      "(15026, 4)\n",
      "\n",
      "Val Data shape: \n",
      "(3757, 4)\n",
      "\n",
      "Test Data shape: \n",
      "(4696, 4)\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Train Data coloumns: \n",
      "['age' 'ethnicity' 'gender' 'img_name']\n",
      "\n",
      "Val Data coloumns: \n",
      "['age' 'ethnicity' 'gender' 'img_name']\n",
      "\n",
      "Test Data coloumns: \n",
      "['age' 'ethnicity' 'gender' 'img_name']\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Train Data Gender Distribution:\n",
      "0    7864\n",
      "1    7162\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "Val Data Gender Distribution:\n",
      "0    1965\n",
      "1    1792\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "Test Data Gender Distribution:\n",
      "0    2456\n",
      "1    2240\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Train Data Ethnicity Distribution:\n",
      "0    6372\n",
      "1    2869\n",
      "3    2524\n",
      "2    2186\n",
      "4    1075\n",
      "Name: ethnicity, dtype: int64\n",
      "\n",
      "Val Data Ethnicity Distribution:\n",
      "0    1593\n",
      "1     717\n",
      "3     632\n",
      "2     547\n",
      "4     268\n",
      "Name: ethnicity, dtype: int64\n",
      "\n",
      "Test Data Ethnicity Distribution:\n",
      "0    1991\n",
      "1     896\n",
      "3     790\n",
      "2     683\n",
      "4     336\n",
      "Name: ethnicity, dtype: int64\n",
      "\n",
      "_____________________________________________\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the datasets using the csv files train, val and test \n",
    "# (3)\n",
    "dfTrain = pd.read_csv('./data/train.csv')\n",
    "dfVal = pd.read_csv('./data/val.csv')\n",
    "dfTest = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# print the shapes of the dataframes \n",
    "# (3)\n",
    "print(f\"Train Data shape: \\n{dfTrain.shape}\\n\")\n",
    "print(f\"Val Data shape: \\n{dfVal.shape}\\n\")\n",
    "print(f\"Test Data shape: \\n{dfTest.shape}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the column names from either one of the dataframes \n",
    "# (1)\n",
    "print(f\"Train Data coloumns: \\n{dfTrain.columns.values}\\n\")\n",
    "print(f\"Val Data coloumns: \\n{dfVal.columns.values}\\n\")\n",
    "print(f\"Test Data coloumns: \\n{dfTest.columns.values}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the proportional distribution of gender in all three datasets(i.e., number of male and female) \n",
    "# (3)\n",
    "print(f\"Train Data Gender Distribution:\\n{dfTrain['gender'].value_counts()}\\n\")\n",
    "print(f\"Val Data Gender Distribution:\\n{dfVal['gender'].value_counts()}\\n\")\n",
    "print(f\"Test Data Gender Distribution:\\n{dfTest['gender'].value_counts()}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the proportional distribution of ethnicity in all three datasets \n",
    "# (3)\n",
    "print(f\"Train Data Ethnicity Distribution:\\n{dfTrain['ethnicity'].value_counts()}\\n\")\n",
    "print(f\"Val Data Ethnicity Distribution:\\n{dfVal['ethnicity'].value_counts()}\\n\")\n",
    "print(f\"Test Data Ethnicity Distribution:\\n{dfTest['ethnicity'].value_counts()}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# plot the age distribution from the training dataset where the x-axis plots the age and the y-axis depicts the count of individuals within each age group. For example, individuals with age=1 are: \n",
    "# (2)\n",
    "\n",
    "graph = dfTrain['age'].value_counts().plot(kind='bar', figsize = (30,12), xlabel = \"Age\", ylabel = \"Age Count\")\n",
    "graph.xaxis.label.set_color('orange')        #setting up X-axis label color to white\n",
    "graph.yaxis.label.set_color('orange')          #setting up Y-axis label color to white\n",
    "graph.tick_params(axis='x', colors='orange')    #setting up X-axis tick color to white\n",
    "graph.tick_params(axis='y', colors='orange')  #setting up Y-axis tick color to white\n",
    "graph.spines['left'].set_color('orange')        # setting up Y-axis tick color to white\n",
    "graph.spines['top'].set_color('orange')         #setting up above X-axis tick color to white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the ImageDataGenerators (22/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15026 validated image filenames.\n",
      "Found 4696 validated image filenames.\n",
      "Found 3757 validated image filenames.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ImageDataGenerator is an iterator.\n",
    "\n",
    "# specify the batch size hyperparameter. You can experiment with different batch sizes\n",
    "batch_size = 16\n",
    "\n",
    "# create the ImageDataGenerator with rescaling that will generate batched tensors representing images with real-time data augmentation\n",
    "# use at least two of the augmentation strategies. For example, fill_mode='nearest'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (3)\n",
    "train_img_gen = ImageDataGenerator(\n",
    "    brightness_range=(0.5,1),\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance to link the image folder and the dataframe.\n",
    "# also include the, batch size, image size and the seed.\n",
    "# make sure to include the following arguments\n",
    "# color_mode='grayscale', class_mode='multi_output'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (5)\n",
    "# TODO\n",
    "\n",
    "train_img_flow = train_img_gen.flow_from_dataframe(\n",
    "    dfTrain,\n",
    "    directory=r\"./data/images/train/\",\n",
    "    x_col= \"img_name\",\n",
    "    y_col= [\"age\", \"ethnicity\", \"gender\"],\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='multi_output',\n",
    "    target_size=(48, 48),\n",
    "    seed=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# similarly, create an ImageDataGenerator for the validation dataset and make sure not to use any of the augmentation strategies except rescaling the image\n",
    "# (2)\n",
    "val_img_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance with the same arguments as above\n",
    "# make sure to specify the following arguments:\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "\n",
    "test_img_flow = val_img_gen.flow_from_dataframe(\n",
    "    dfTest,\n",
    "    directory=r\"./data/images/test/\",\n",
    "    x_col= \"img_name\",\n",
    "    y_col= [\"age\", \"ethnicity\", \"gender\"],\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='multi_output',\n",
    "    shuffle=False,\n",
    "    target_size=(48, 48),\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the val_img_gen instance to link the test dataframe and the test data folder\n",
    "# In addition, make sure to specify the following arguments\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "val_img_flow = val_img_gen.flow_from_dataframe(\n",
    "    dfVal,\n",
    "    directory=r\"./data/images/val/\",\n",
    "    x_col= \"img_name\",\n",
    "    y_col= [\"age\", \"ethnicity\", \"gender\"],\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='multi_output',\n",
    "    shuffle=False,\n",
    "    target_size=(48, 48),\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# enumerate through the validation data generator created above and plot first grayscale image \n",
    "# (2)\n",
    "for i, element in enumerate(val_img_flow):\n",
    "    plt.imshow(element[0][0],cmap=plt.cm.binary)\n",
    "    plt.show()    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model (44/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 46, 46, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 23, 23, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 21, 21, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 128)    73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dense_Layer_1 (Dense)           (None, 128)          1048704     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Dense_Layer_2 (Dense)           (None, 128)          1048704     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          1048704     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Dense_Age (Dense)               (None, 1)            129         Dense_Layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dense_Ethnicity (Dense)         (None, 5)            645         Dense_Layer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dense_Gender (Dense)            (None, 2)            258         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,239,816\n",
      "Trainable params: 3,239,816\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:759 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:409 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:176 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:612 update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3208 accuracy  **\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 5) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11624/3460739520.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;31m# (5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_img_flow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_img_flow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:759 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:409 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:176 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:612 update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3208 accuracy  **\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n    C:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 5) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# specify the model input with the required shape \n",
    "# (1)\n",
    "model_input = keras.Input(shape=(48, 48, 1)) \n",
    "\n",
    "# The shared layers\n",
    "# Include at least one Conv2D layer, MaxPooling2D layer and a Flatten layer\n",
    "# you can have as many layers as possible, but make sure not to overfit your model using the training data\n",
    "# (10)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(model_input) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x) \n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x) \n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Task specific layers\n",
    "# Include at least one Dense layer as a task specific layer before generating the output for age\n",
    "\n",
    "# (2)\n",
    "\n",
    "dense_layer_1 = layers.Dense(128, activation=\"relu\", name=\"Dense_Layer_1\")(x) \n",
    "\n",
    "#model = keras.Model(inputs=model_input, outputs=dense_layer)\n",
    "\n",
    "# Include the age output and make sure to include the following arguments\n",
    "# activation='linear', name='xxx'(any name)\n",
    "# make sure to name your output layers so that different metrics to be used can be linked accordingly\n",
    "# please note that the age prediction is a regression task\n",
    "\n",
    "# (2)\n",
    "age_output = layers.Dense(1, activation=\"linear\", name=\"Dense_Age\")(dense_layer_1)\n",
    "#age_output = layers.Flatten()(age_output)\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for ethnicity prediction\n",
    "# (2)\n",
    "dense_layer_2 = layers.Dense(128, activation=\"relu\", name=\"Dense_Layer_2\")(x) \n",
    "\n",
    "# Include the ethnicity output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a multi-class classification task\n",
    "# (2)\n",
    "\n",
    "eth_output = layers.Dense(5, activation=\"softmax\", name=\"Dense_Ethnicity\")(dense_layer_2)\n",
    "#eth_output = layers.Flatten()(eth_output)\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for gender prediction\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "dense_layer_3 = layers.Dense(128, activation=\"relu\")(x) \n",
    "\n",
    "# Include the gender output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a binary classification task\n",
    "\n",
    "# (2)\n",
    "\n",
    "gen_output = layers.Dense(2, activation=\"relu\", name=\"Dense_Gender\")(dense_layer_3)\n",
    "#gen_output = layers.Flatten()(gen_output)\n",
    "\n",
    "# create the model with the required input and the outputs.\n",
    "# pelase make sure that the outputs can be included in a list and make sure to keep note of the order\n",
    "# (3)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=[age_output, eth_output, gen_output])\n",
    "\n",
    "\n",
    "# print the model summary\n",
    "# (0.5)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Instantiate the optimizer with the learning rate. You can start with the learning rate 1e-3(0.001).\n",
    "# Both the optimizer and the learning rate are hyperparameters that you can finetune\n",
    "# For example, you can start with the \"RMSprop\" optimizer\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "\n",
    "# specify the losses to be used for each task: age, ethnicity and gender prediction \n",
    "# (0.5)\n",
    "losses = ['MeanAbsoluteError', 'sparse_categorical_crossentropy', 'binary_crossentropy']\n",
    "\n",
    "# compile the model with the optimizer, loss, loss_weights and the metrics for each task\n",
    "# apply the following weights to the losses to balance the contribution of each loss to the total loss\n",
    "# loss_weights=[0.001, 0.5, 0.5]\n",
    "# please remember to use the relevant metric for each task by assigning it to the correct output\n",
    "# (2)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=losses, metrics=['MeanAbsoluteError', 'Accuracy' , 'BinaryAccuracy'], loss_weights=[0.001, 0.5, 0.5])\n",
    "\n",
    "# Define the callbacks\n",
    "# EarlyStopping: monitor the validation loss while waiting for 3 epochs before stopping\n",
    "# can restore the best weights\n",
    "# (2)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "# (2)\n",
    "\n",
    "checkpoints = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./models/checkpoints',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "# (2)\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir='./logs/tensorlog'\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "# reduce the learning rate by a factor of 0.1 after waiting for 2 epochs while monitoring validation loss\n",
    "# specify a minimum learning rate to be used\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "# In addition please specify the following arguments\n",
    "# steps_per_epoch=len(df_train)/batch_size\n",
    "# validation_steps=len(df_val)/batch_size\n",
    "# (5)\n",
    "\n",
    "model.fit(\n",
    "    x=train_img_flow,\n",
    "    validation_data=val_img_flow,\n",
    "    epochs=10, \n",
    "    batch_size=64, \n",
    "    callbacks=[reduce_lr, early_stop, checkpoints, tensorboard],\n",
    "    steps_per_epoch=len(dfTrain)/batch_size,\n",
    "    validation_steps=len(dfVal)/batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions on test data (14/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 3s 10ms/step - loss: 0.5590 - Dense_Age_loss: 9.1884 - Dense_Ethnicity_loss: 0.6609 - Dense_Gender_loss: 0.4388 - Dense_Age_mean_absolute_error: 9.1884 - Dense_Age_Accuracy: 0.0322 - Dense_Age_binary_accuracy: 0.0322 - Dense_Ethnicity_mean_absolute_error: 1.2422 - Dense_Ethnicity_Accuracy: 0.7745 - Dense_Ethnicity_binary_accuracy: 0.3793 - Dense_Gender_mean_absolute_error: 0.3331 - Dense_Gender_Accuracy: 0.6420 - Dense_Gender_binary_accuracy: 0.8821\n",
      "\n",
      "Dense_Ethnicity_Accuracy:\n",
      "0.7744889259338379\n",
      "\n",
      "\n",
      "Dense_Gender_Binary_Accuracy:\n",
      "0.8821337223052979\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained model using the test generator\n",
    "# print only the test accuracy for ethnicity and gender predictions\n",
    "(4)\n",
    "test_evals = model.evaluate(\n",
    "    x=test_img_flow\n",
    ")\n",
    "print(\"\\nDense_Ethnicity_Accuracy:\")\n",
    "print(test_evals[8])\n",
    "print(\"\\n\\nDense_Gender_Binary_Accuracy:\")\n",
    "print(test_evals[12])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 3s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      1991\n",
      "           1       0.82      0.80      0.81       896\n",
      "           2       0.82      0.80      0.81       683\n",
      "           3       0.68      0.74      0.71       790\n",
      "           4       0.43      0.12      0.19       336\n",
      "\n",
      "    accuracy                           0.77      4696\n",
      "   macro avg       0.71      0.67      0.67      4696\n",
      "weighted avg       0.76      0.77      0.76      4696\n",
      "\n",
      "[0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.69      2456\n",
      "           1       0.67      0.49      0.57      2240\n",
      "\n",
      "    accuracy                           0.64      4696\n",
      "   macro avg       0.65      0.64      0.63      4696\n",
      "weighted avg       0.65      0.64      0.63      4696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# generate predictions using the test generator\n",
    "(2)\n",
    "predictions = model.predict(\n",
    "    x=test_img_flow,\n",
    "    batch_size=64, \n",
    "    callbacks=[reduce_lr, early_stop, checkpoints, tensorboard],\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "\n",
    "# extract the ethnicity predictions\n",
    "(2)\n",
    "\n",
    "eth_pred_lbls = np.argmax(predictions[1], axis=1)\n",
    "\n",
    "\n",
    "# print the classification report for predicting ethnicity\n",
    "(2)\n",
    "\n",
    "eth_cr = classification_report(dfTest['ethnicity'].values.ravel(), eth_pred_lbls)\n",
    "print(eth_cr)\n",
    "\n",
    "# extract the gender predictions where probabilities above 0.5 are considered class 1 and if not, class 0\n",
    "(2)\n",
    "\n",
    "gen_pred_lbls = np.argmax(predictions[2], axis=1)\n",
    "print(np.unique(gen_pred_lbls))\n",
    "\n",
    "# print the classification report for predicting gender\n",
    "(2)\n",
    "gen_cr = classification_report(dfTest['gender'].values.ravel(), gen_pred_lbls)\n",
    "print(gen_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Present prediction results on test data(5/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present your findings for 5 different runs by fine-tuning the hyperparameters. The results table must contain the following fields\n",
    "- A minimum of 5 hyperparameters that you have fine-tuned\n",
    "- Mean absolute error for age\n",
    "- Accuracy for ethnicity prediction\n",
    "- Accuracy for gender prediction\n",
    "Please use a table format similar to the one mentioned below when presenting the results.\n",
    "\n",
    "| Hyperparameters | Age(MAE) | Ethnicity(Accuracy)| Gender(Accuracy) |\n",
    "|-----------------|----------|--------------------|------------------|\n",
    "|Batch Size =32   | 33.192         |  0.789                  |   0.845               |\n",
    "|Epoch size = 13  |   33.192       |         0.783           |  0.657                |\n",
    "|Learning Rate  =0.0001|   33.192  |          0.760          |        0.720          |\n",
    "|Optimizer = Adam      |   33.192       |    0.716                |    0.569              |\n",
    "|Layers   Add Conv2D and a DepthWise2D              |     33.192     |      0.760              |      0.704            |\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
