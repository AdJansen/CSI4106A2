{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for reproducibility purposes\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# load tensorboard extension\n",
    "%reload_ext tensorboard\n",
    "# specify the log directory where the tensorboard logs will be written\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the relevant datasets (15/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets using the csv files train, val and test \n",
    "# (3)\n",
    "dfTrain = pd.read_csv('./data/train.csv')\n",
    "dfVal = pd.read_csv('./data/val.csv')\n",
    "dfTest = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# print the shapes of the dataframes \n",
    "# (3)\n",
    "print(f\"Train Data shape: \\n{dfTrain.shape}\\n\")\n",
    "print(f\"Val Data shape: \\n{dfVal.shape}\\n\")\n",
    "print(f\"Test Data shape: \\n{dfTest.shape}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the column names from either one of the dataframes \n",
    "# (1)\n",
    "print(f\"Train Data coloumns: \\n{dfTrain.columns.values}\\n\")\n",
    "print(f\"Val Data coloumns: \\n{dfVal.columns.values}\\n\")\n",
    "print(f\"Test Data coloumns: \\n{dfTest.columns.values}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the proportional distribution of gender in all three datasets(i.e., number of male and female) \n",
    "# (3)\n",
    "print(f\"Train Data Gender Distribution:\\n{dfTrain['gender'].value_counts()}\\n\")\n",
    "print(f\"Val Data Gender Distribution:\\n{dfVal['gender'].value_counts()}\\n\")\n",
    "print(f\"Test Data Gender Distribution:\\n{dfTest['gender'].value_counts()}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# print the proportional distribution of ethnicity in all three datasets \n",
    "# (3)\n",
    "print(f\"Train Data Ethnicity Distribution:\\n{dfTrain['ethnicity'].value_counts()}\\n\")\n",
    "print(f\"Val Data Ethnicity Distribution:\\n{dfVal['ethnicity'].value_counts()}\\n\")\n",
    "print(f\"Test Data Ethnicity Distribution:\\n{dfTest['ethnicity'].value_counts()}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "# plot the age distribution from the training dataset where the x-axis plots the age and the y-axis depicts the count of individuals within each age group. For example, individuals with age=1 are: \n",
    "# (2)\n",
    "\n",
    "graph = dfTrain['age'].value_counts().plot(kind='bar', figsize = (30,12), xlabel = \"Age\", ylabel = \"Age Count\")\n",
    "graph.xaxis.label.set_color('orange')        #setting up X-axis label color to white\n",
    "graph.yaxis.label.set_color('orange')          #setting up Y-axis label color to white\n",
    "graph.tick_params(axis='x', colors='orange')    #setting up X-axis tick color to white\n",
    "graph.tick_params(axis='y', colors='orange')  #setting up Y-axis tick color to white\n",
    "graph.spines['left'].set_color('orange')        # setting up Y-axis tick color to white\n",
    "graph.spines['top'].set_color('orange')         #setting up above X-axis tick color to white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the ImageDataGenerators (22/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator is an iterator.\n",
    "\n",
    "# specify the batch size hyperparameter. You can experiment with different batch sizes\n",
    "batch_size = 16\n",
    "\n",
    "# create the ImageDataGenerator with rescaling that will generate batched tensors representing images with real-time data augmentation\n",
    "# use at least two of the augmentation strategies. For example, fill_mode='nearest'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (3)\n",
    "train_img_gen = ImageDataGenerator(\n",
    "    brightness_range=(0.5,1),\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    rescale=2\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance to link the image folder and the dataframe.\n",
    "# also include the, batch size, image size and the seed.\n",
    "# make sure to include the following arguments\n",
    "# color_mode='grayscale', class_mode='multi_output'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (5)\n",
    "# TODO\n",
    "\n",
    "train_img_gen.flow_from_dataframe(\n",
    "    dfTrain,\n",
    "    directory=r\"./data/images/train/\",\n",
    "    x_col= \"img_name\",\n",
    "    y_col= [\"age\", \"ethnicity\", \"gender\"],\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='multi_output'\n",
    ")\n",
    "\n",
    "# similarly, create an ImageDataGenerator for the validation dataset and make sure not to use any of the augmentation strategies except rescaling the image\n",
    "# (2)\n",
    "val_img_gen = ImageDataGenerator(\n",
    "    rescale = 2\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance with the same arguments as above\n",
    "# make sure to specify the following arguments:\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "# TODO\n",
    "test_img_gen = ImageDataGenerator(\n",
    "    brightness_range=(0.5,1),\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    rescale=2\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "test_img_gen.flow_from_dataframe(\n",
    "    dfTest,\n",
    "    directory=r\"./data/images/test/\",\n",
    "    x_col= \"img_name\",\n",
    "    y_col= [\"age\", \"ethnicity\", \"gender\"],\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='multi_output',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the val_img_gen instance to link the test dataframe and the test data folder\n",
    "# In addition, make sure to specify the following arguments\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "# TODO\n",
    "val_df_flow = val_img_gen.flow_from_dataframe(\n",
    "    dfVal,\n",
    "    directory=r\"./data/images/val/\",\n",
    "    x_col= \"img_name\",\n",
    "    y_col= [\"age\", \"ethnicity\", \"gender\"],\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='multi_output',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# enumerate through the validation data generator created above and plot first grayscale image \n",
    "# (2)\n",
    "for i, element in enumerate(val_df_flow):\n",
    "    plt.imshow(element[0][0],cmap=plt.cm.binary)\n",
    "    plt.show()    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model (44/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the model input with the required shape \n",
    "# (1)\n",
    "model_input = keras.Input(shape=(96, 96, 1)) \n",
    "\n",
    "# The shared layers\n",
    "# Include at least one Conv2D layer, MaxPooling2D layer and a Flatten layer\n",
    "# you can have as many layers as possible, but make sure not to overfit your model using the training data\n",
    "# (10)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(model_input) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x) \n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x) \n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Task specific layers\n",
    "# Include at least one Dense layer as a task specific layer before generating the output for age\n",
    "\n",
    "# (2)\n",
    "\n",
    "dense_layer_1 = layers.Dense(128, activation=\"linear\", name=\"Dense_Layer_1\")(x) \n",
    "\n",
    "#model = keras.Model(inputs=model_input, outputs=dense_layer)\n",
    "\n",
    "# Include the age output and make sure to include the following arguments\n",
    "# activation='linear', name='xxx'(any name)\n",
    "# make sure to name your output layers so that different metrics to be used can be linked accordingly\n",
    "# please note that the age prediction is a regression task\n",
    "\n",
    "# (2)\n",
    "age_output = layers.Dense(10, activation=\"linear\", name=\"Dense_Age\")(dense_layer_1)\n",
    "\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for ethnicity prediction\n",
    "# (2)\n",
    "dense_layer_2 = layers.Dense(128, activation=\"softmax\", name=\"Dense_Layer_2\")(x) \n",
    "\n",
    "# Include the ethnicity output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a multi-class classification task\n",
    "# (2)\n",
    "\n",
    "eth_output = layers.Dense(10, activation=\"softmax\", name=\"Dense_Ethnicity\")(dense_layer_2)\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for gender prediction\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "dense_layer_3 = layers.Dense(128, activation=\"softmax\", name=\"Dense_Layer_3\")(x) \n",
    "\n",
    "# Include the gender output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a binary classification task\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "gen_output = layers.Dense(10, activation=\"softmax\", name=\"Dense_Gender\")(dense_layer_3)\n",
    "\n",
    "# create the model with the required input and the outputs.\n",
    "# pelase make sure that the outputs can be included in a list and make sure to keep note of the order\n",
    "# (3)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=[age_output, eth_output, gen_output])\n",
    "\n",
    "\n",
    "# print the model summary\n",
    "# (0.5)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Instantiate the optimizer with the learning rate. You can start with the learning rate 1e-3(0.001).\n",
    "# Both the optimizer and the learning rate are hyperparameters that you can finetune\n",
    "# For example, you can start with the \"RMSprop\" optimizer\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "# specify the losses to be used for each task: age, ethnicity and gender prediction \n",
    "# (0.5)\n",
    "losses = ['MeanSquaredError', 'sparse_categorical_crossentropy', 'BinaryCrossentropy']\n",
    "\n",
    "# compile the model with the optimizer, loss, loss_weights and the metrics for each task\n",
    "# apply the following weights to the losses to balance the contribution of each loss to the total loss\n",
    "# loss_weights=[0.001, 0.5, 0.5]\n",
    "# please remember to use the relevant metric for each task by assigning it to the correct output\n",
    "# (2)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=losses, metrics=['accuracy', 'CategoricalCrossentropy' , 'BinaryAccuracy'], loss_weights=[0.001, 0.5, 0.5])\n",
    "\n",
    "# Define the callbacks\n",
    "# EarlyStopping: monitor the validation loss while waiting for 3 epochs before stopping\n",
    "# can restore the best weights\n",
    "# (2)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "# (2)\n",
    "\n",
    "checkpoints = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./models/checkpoints',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "# (2)\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir='./logs/tensorlog'\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "# reduce the learning rate by a factor of 0.1 after waiting for 2 epochs while monitoring validation loss\n",
    "# specify a minimum learning rate to be used\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "# In addition please specify the following arguments\n",
    "# steps_per_epoch=len(df_train)/batch_size\n",
    "# validation_steps=len(df_val)/batch_size\n",
    "# (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions on test data (14/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the trained model using the test generator\n",
    "# print only the test accuracy for ethnicity and gender predictions\n",
    "(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions using the test generator\n",
    "(2)\n",
    "\n",
    "# extract the ethnicity predictions\n",
    "(2)\n",
    "# print the classification report for predicting ethnicity\n",
    "(2)\n",
    "\n",
    "# extract the gender predictions where probabilities above 0.5 are considered class 1 and if not, class 0\n",
    "(2)\n",
    "# print the classification report for predicting gender\n",
    "(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Present prediction results on test data(5/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present your findings for 5 different runs by fine-tuning the hyperparameters. The results table must contain the following fields\n",
    "- A minimum of 5 hyperparameters that you have fine-tuned\n",
    "- Mean absolute error for age\n",
    "- Accuracy for ethnicity prediction\n",
    "- Accuracy for gender prediction\n",
    "Please use a table format similar to the one mentioned below when presenting the results.\n",
    "\n",
    "| Hyperparameters | Age(MAE) | Ethnicity(Accuracy)| Gender(Accuracy) |\n",
    "|-----------------|----------|--------------------|------------------|\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
